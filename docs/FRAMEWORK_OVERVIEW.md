# Test Automation Framework
### Enterprise-Grade Quality Assurance for Modern Web Applications

---

## Executive Summary

This test automation framework delivers **fast, reliable, and maintainable** end-to-end testing for web applications. Built on Microsoft's Playwright with TypeScript, it combines industry best practices with modern tooling to reduce testing costs while increasing coverage and confidence.

### Key Metrics

| Metric | Value |
|--------|-------|
| Test Execution Time | ~10 seconds (25 tests, parallel) |
| Browser Coverage | Chrome, Firefox, Safari |
| Code Coverage Approach | Data-driven (add tests without code changes) |
| Maintenance Overhead | Low (centralized selectors, typed configs) |

---

## Architecture Overview

```mermaid
flowchart TB
    subgraph TestLayer["Test Layer"]
        TestSpecs["Test Specifications<br/>(.spec.ts files)"]
        TestData["Test Data<br/>(JSON files)"]
    end

    subgraph FrameworkLayer["Framework Layer"]
        Fixtures["Playwright Fixtures<br/>(Dependency Injection)"]
        PageObjects["Page Objects<br/>(UI Abstraction)"]
        Config["Configuration<br/>(Environment Management)"]
    end

    subgraph InfraLayer["Infrastructure Layer"]
        Playwright["Playwright Engine"]
        Browsers["Browser Engines<br/>Chromium | Firefox | WebKit"]
        Reporting["HTML Reports<br/>Screenshots | Videos | Traces"]
    end

    TestSpecs --> Fixtures
    TestData --> TestSpecs
    Fixtures --> PageObjects
    PageObjects --> Config
    Fixtures --> Playwright
    Playwright --> Browsers
    Playwright --> Reporting

    style TestLayer fill:#e1f5fe
    style FrameworkLayer fill:#fff3e0
    style InfraLayer fill:#f3e5f5
```

---

## Core Design Principles

### 1. Data-Driven Testing

Tests are defined in JSON, not code. This means **QA engineers can add test cases without touching TypeScript**.

```mermaid
flowchart LR
    subgraph Input["Test Definition"]
        JSON["test-cases.json<br/>â”â”â”â”â”â”â”â”â”â”â”â”â”â”<br/>TC001: Verify login<br/>TC002: Verify cart<br/>TC003: Verify checkout"]
    end

    subgraph Engine["Test Engine"]
        Loop["For each test case:<br/>1. Navigate<br/>2. Verify<br/>3. Assert"]
    end

    subgraph Output["Results"]
        Results["âœ“ TC001 Pass<br/>âœ“ TC002 Pass<br/>âœ— TC003 Fail"]
    end

    JSON --> Loop --> Results

    style Input fill:#c8e6c9
    style Engine fill:#fff9c4
    style Output fill:#ffcdd2
```

**Adding a new test is as simple as:**

```json
{
  "id": "TC007",
  "name": "Verify checkout flow",
  "project": "E-Commerce",
  "taskName": "Complete purchase",
  "expectedColumn": "Done",
  "expectedTags": ["Critical", "Regression"]
}
```

No code changes. No deployments. Just data.

---

### 2. Page Object Model (POM)

UI interactions are **encapsulated** in reusable page objects. When the UI changes, updates happen in one place.

```mermaid
flowchart TB
    subgraph Tests["Test Files"]
        Test1["Login Test"]
        Test2["Checkout Test"]
        Test3["Profile Test"]
    end

    subgraph PageObjects["Page Objects"]
        LoginPage["LoginPage<br/>â”â”â”â”â”â”â”â”â”â”<br/>login()<br/>logout()<br/>verifyLoggedIn()"]
        CartPage["CartPage<br/>â”â”â”â”â”â”â”â”â”â”<br/>addItem()<br/>removeItem()<br/>checkout()"]
        ProfilePage["ProfilePage<br/>â”â”â”â”â”â”â”â”â”â”<br/>updateName()<br/>changePassword()"]
    end

    subgraph App["Application"]
        UI["Web Application UI"]
    end

    Test1 --> LoginPage
    Test2 --> LoginPage
    Test2 --> CartPage
    Test3 --> LoginPage
    Test3 --> ProfilePage

    LoginPage --> UI
    CartPage --> UI
    ProfilePage --> UI

    style Tests fill:#e3f2fd
    style PageObjects fill:#fff8e1
    style App fill:#fce4ec
```

**Benefits:**
- **Single Point of Change** - Selector updates in one file, not dozens of tests
- **Readable Tests** - `await cartPage.addItem('SKU-123')` vs complex locator chains
- **Reusable Actions** - Common workflows shared across test suites

---

### 3. Smart Authentication

Login happens **once**, then the session is reused across all tests. This dramatically reduces execution time.

```mermaid
sequenceDiagram
    participant Setup as Auth Setup
    participant Storage as Session Storage
    participant Test1 as Test 1
    participant Test2 as Test 2
    participant Test3 as Test 3
    participant App as Application

    Setup->>App: Login (username/password)
    App-->>Setup: Session cookies
    Setup->>Storage: Save auth state

    par Parallel Execution
        Test1->>Storage: Load auth state
        Storage-->>Test1: Cookies
        Test1->>App: Access protected page âœ“

        Test2->>Storage: Load auth state
        Storage-->>Test2: Cookies
        Test2->>App: Access protected page âœ“

        Test3->>Storage: Load auth state
        Storage-->>Test3: Cookies
        Test3->>App: Access protected page âœ“
    end
```

**Impact:** Tests run **3-5x faster** by eliminating redundant login flows.

---

## Test Execution Flow

```mermaid
flowchart TB
    Start([npm test]) --> LoadConfig[Load Configuration]
    LoadConfig --> AuthSetup{Auth Setup<br/>Required?}

    AuthSetup -->|Yes| Login[Execute Login]
    Login --> SaveState[Save Session State]
    SaveState --> LoadTests
    AuthSetup -->|No| LoadTests[Load Test Cases]

    LoadTests --> ParseJSON[Parse test-cases.json]
    ParseJSON --> GenerateTests[Generate Test Suite]

    GenerateTests --> Execute[Execute Tests in Parallel]

    Execute --> Test1[Test 1]
    Execute --> Test2[Test 2]
    Execute --> Test3[Test N...]

    Test1 --> Results
    Test2 --> Results
    Test3 --> Results

    Results[Collect Results] --> Report{Generate<br/>Report}

    Report --> HTML[HTML Report]
    Report --> Screenshots[Failure Screenshots]
    Report --> Videos[Retry Videos]
    Report --> Traces[Debug Traces]

    HTML --> End([Complete])
    Screenshots --> End
    Videos --> End
    Traces --> End

    style Start fill:#4caf50,color:#fff
    style End fill:#4caf50,color:#fff
    style Execute fill:#2196f3,color:#fff
```

---

## Cross-Browser Testing

One test suite runs across **all major browser engines** with a single command.

```mermaid
flowchart LR
    subgraph TestSuite["Test Suite"]
        Tests["25 Test Cases"]
    end

    subgraph Browsers["Browser Matrix"]
        Chrome["Chrome<br/>(Chromium)"]
        Firefox["Firefox<br/>(Gecko)"]
        Safari["Safari<br/>(WebKit)"]
    end

    subgraph Coverage["Coverage"]
        Desktop["Desktop: 95%+ users"]
        Mobile["Mobile: Ready*"]
    end

    Tests --> Chrome
    Tests --> Firefox
    Tests --> Safari

    Chrome --> Desktop
    Firefox --> Desktop
    Safari --> Desktop

    style TestSuite fill:#e8f5e9
    style Browsers fill:#e3f2fd
    style Coverage fill:#fff3e0
```

| Command | Browsers | Use Case |
|---------|----------|----------|
| `npm test` | Chromium | Fast development feedback |
| `npm run test:browsers` | All 3 | Pre-release validation |
| `npm run test:webkit` | Safari | macOS/iOS compatibility |

*Mobile viewport testing available as future enhancement

---

## Project Structure

```
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ pages/                    # Page Object Model
â”‚   â”‚   â”œâ”€â”€ base.page.ts          # Common functionality
â”‚   â”‚   â”œâ”€â”€ login.page.ts         # Authentication
â”‚   â”‚   â””â”€â”€ project.page.ts       # Main application
â”‚   â”‚
â”‚   â”œâ”€â”€ fixtures/                 # Dependency Injection
â”‚   â”‚   â””â”€â”€ test.fixture.ts       # Page object provisioning
â”‚   â”‚
â”‚   â”œâ”€â”€ types/                    # Type Safety
â”‚   â”‚   â””â”€â”€ test-data.types.ts    # Test case interfaces
â”‚   â”‚
â”‚   â””â”€â”€ utils/                    # Configuration
â”‚       â””â”€â”€ config.ts             # Environment management
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ test-cases.json           # Test definitions (no-code)
â”‚
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ auth.setup.ts             # One-time authentication
â”‚   â”œâ”€â”€ auth-negative.spec.ts     # Negative auth tests (3)
â”‚   â”œâ”€â”€ board-structure.spec.ts   # Board structure tests (7)
â”‚   â”œâ”€â”€ navigation.spec.ts        # Navigation tests (3)
â”‚   â”œâ”€â”€ task-verification.spec.ts # Data-driven task tests (11)
â”‚   â””â”€â”€ demo-failures.spec.ts     # Demo failures (skipped)
â”‚
â””â”€â”€ playwright.config.ts          # Framework configuration
```

---

## Reporting & Debugging

### HTML Test Reports

Every test run generates a detailed HTML report with:

- **Pass/Fail Summary** - At-a-glance results
- **Step-by-Step Breakdown** - What each test did
- **Failure Screenshots** - Visual evidence of issues
- **Video Recording** - Full replay of failed tests
- **Trace Files** - Time-travel debugging

```mermaid
flowchart LR
    subgraph Artifacts["Test Artifacts"]
        direction TB
        Report["HTML Report<br/>ğŸ“Š"]
        Screenshots["Screenshots<br/>ğŸ“¸"]
        Videos["Videos<br/>ğŸ¬"]
        Traces["Traces<br/>ğŸ”"]
    end

    subgraph Actions["Developer Actions"]
        View["View Results"]
        Debug["Debug Failures"]
        Share["Share with Team"]
    end

    Report --> View
    Screenshots --> Debug
    Videos --> Debug
    Traces --> Debug
    Report --> Share

    style Artifacts fill:#e8eaf6
    style Actions fill:#fce4ec
```

### Timestamped Report History

```
playwright-report/
â”œâ”€â”€ report-2024-01-15_14-30-45/   # Monday run
â”œâ”€â”€ report-2024-01-15_16-22-10/   # After fixes
â””â”€â”€ report-2024-01-16_09-15-33/   # Tuesday regression
```

Compare results across runs. Track improvements over time.

---

## Quality Assurance Built-In

```mermaid
flowchart LR
    subgraph Checks["Automated Checks"]
        ESLint["ESLint<br/>Code Quality"]
        TypeScript["TypeScript<br/>Type Safety"]
        Prettier["Prettier<br/>Formatting"]
    end

    subgraph Gates["Quality Gates"]
        Compile["Compilation<br/>Must Pass"]
        Lint["Linting<br/>Must Pass"]
        Tests["Tests<br/>Must Pass"]
    end

    ESLint --> Lint
    TypeScript --> Compile
    Prettier --> Lint

    Compile --> CI[CI/CD Pipeline]
    Lint --> CI
    Tests --> CI

    CI --> Deploy{Deploy?}
    Deploy -->|All Pass| Yes[âœ“ Release]
    Deploy -->|Any Fail| No[âœ— Block]

    style Checks fill:#e8f5e9
    style Gates fill:#fff3e0
    style Yes fill:#4caf50,color:#fff
    style No fill:#f44336,color:#fff
```

---

## Docker & CI/CD Integration

The framework is **container-ready** for seamless CI/CD pipeline integration.

### Container Architecture

```mermaid
flowchart TB
    subgraph CI["CI/CD Pipeline"]
        Trigger["Git Push / PR"]
        Build["Build Docker Image"]
        Run["Run Tests in Container"]
        Artifacts["Extract Reports"]
        Notify["Notify Team"]
    end

    subgraph Container["Docker Container"]
        direction TB
        Playwright["Playwright Runtime"]
        Browsers["Pre-installed Browsers<br/>Chromium âœ“"]
        Tests["Test Framework"]
        Results["Test Results"]
    end

    Trigger --> Build
    Build --> Run
    Run --> Container
    Container --> Artifacts
    Artifacts --> Notify

    Playwright --> Browsers
    Tests --> Playwright
    Playwright --> Results

    style CI fill:#e3f2fd
    style Container fill:#fff3e0
```

### Docker Usage

```bash
# Build the test image
docker build -t playwright-tests .

# Run tests (default: Chromium)
docker run --rm playwright-tests

# Run with report extraction
docker run --rm \
  -v $(pwd)/reports:/app/playwright-report \
  playwright-tests

# Run all browsers
docker run --rm playwright-tests npm run test:browsers

# Pass custom environment variables
docker run --rm \
  -e BASE_URL=https://staging.example.com \
  -e USERNAME=testuser \
  -e PASSWORD=testpass \
  playwright-tests
```

### CI Pipeline Examples

#### GitHub Actions

```yaml
name: E2E Tests

on: [push, pull_request]

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Build test image
        run: docker build -t playwright-tests .

      - name: Run tests
        run: |
          docker run --rm \
            -v ${{ github.workspace }}/reports:/app/playwright-report \
            playwright-tests

      - name: Upload report
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: playwright-report
          path: reports/
```

#### GitLab CI

```yaml
e2e-tests:
  image: docker:latest
  services:
    - docker:dind
  script:
    - docker build -t playwright-tests .
    - docker run --rm -v $(pwd)/reports:/app/playwright-report playwright-tests
  artifacts:
    when: always
    paths:
      - reports/
```

#### Jenkins Pipeline

```groovy
pipeline {
    agent any
    stages {
        stage('Build') {
            steps {
                sh 'docker build -t playwright-tests .'
            }
        }
        stage('Test') {
            steps {
                sh 'docker run --rm -v $(pwd)/reports:/app/playwright-report playwright-tests'
            }
        }
    }
    post {
        always {
            publishHTML([
                reportDir: 'reports',
                reportFiles: 'index.html',
                reportName: 'Playwright Report'
            ])
        }
    }
}
```

### CI/CD Flow

```mermaid
sequenceDiagram
    participant Dev as Developer
    participant Git as Git Repository
    participant CI as CI Pipeline
    participant Docker as Docker Container
    participant Report as Test Report

    Dev->>Git: Push code
    Git->>CI: Trigger pipeline

    CI->>Docker: Build image
    Docker-->>CI: Image ready

    CI->>Docker: Run tests
    Docker->>Docker: Execute Playwright
    Docker-->>CI: Tests complete

    CI->>Report: Extract artifacts
    CI->>Dev: Notify (pass/fail)

    Dev->>Report: Review results
```

### Container Benefits

| Benefit | Description |
|---------|-------------|
| **Consistency** | Same environment locally and in CI |
| **Isolation** | No system dependencies to manage |
| **Speed** | Pre-installed browsers, no setup time |
| **Portability** | Works on any Docker-capable host |
| **Scalability** | Easy to parallelize across containers |

---

## Getting Started

### Prerequisites

- Node.js 18+
- npm or yarn

### Quick Start

```bash
# 1. Install dependencies
npm install

# 2. Install browsers
npx playwright install --with-deps

# 3. Run tests
npm test

# 4. View report
npm run report
```

### First Test in 60 Seconds

1. Open `data/test-cases.json`
2. Add a new test case object
3. Run `npm test`
4. See your test in the report

---

## Comparison: Before & After

| Aspect | Manual Testing | This Framework |
|--------|---------------|----------------|
| Execution Time | Hours | Minutes |
| Human Error | High | Eliminated |
| Repeatability | Variable | 100% Consistent |
| Browser Coverage | Limited | All Major Browsers |
| Documentation | Manual | Auto-Generated Reports |
| Regression Testing | Expensive | Free (re-run) |
| Night/Weekend Runs | Not Feasible | Fully Automated |

---

## Roadmap

```mermaid
gantt
    title Framework Enhancement Roadmap
    dateFormat  YYYY-MM
    section Foundation
    Core Framework     :done, 2024-01, 2024-01
    Cross-Browser      :done, 2024-01, 2024-01
    Docker/CI          :done, 2024-01, 2024-02
    section Enhancements
    Mobile Viewports   :active, 2024-02, 2024-02
    API Testing        :2024-02, 2024-03
    Visual Regression  :2024-03, 2024-04
    section Integration
    Slack Notifications:2024-03, 2024-03
    Dashboard          :2024-04, 2024-04
```

---

## Support & Documentation

| Resource | Location |
|----------|----------|
| Technical README | `README.md` |
| Framework Standards | `.claude/skills/framework-standards.md` |
| Adding Tests Guide | `.claude/skills/adding-tests.md` |
| Code Review Checklist | `.claude/skills/sdet-review.md` |

---

<div align="center">

**Built with Playwright + TypeScript**

*Reliable. Maintainable. Scalable.*

> **Experimental Alternative:** A Python Behave (BDD) implementation covering the same 25 scenarios is available in `python-behave/`. See [`python-behave/docs/README.md`](../python-behave/docs/README.md) for details.

</div>
